{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged-Head Sequence Extraction from High Attention Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from high_attention import kmer2seq, attention_seq\n",
    "\n",
    "# Loading in attention scores from atten.npy\n",
    "attention_file = \"../output/positive_evaulation/atten.npy\"\n",
    "atten_scores = np.load(attention_file)\n",
    "\n",
    "# # Load in the Sequences from TSV file.\n",
    "# sequences_path = \"../data/full_data_tsv/positive.tsv\"\n",
    "# sequences = pd.read_csv(sequences_path, sep=\"\\t\", header=0)\n",
    "# sequences.columns = [\"sequence\", \"label\"]\n",
    "# sequences[\"seq\"] = sequences[\"sequence\"].apply(kmer2seq)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading in Logits for Class Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 26157 positive samples being tested.\n"
     ]
    }
   ],
   "source": [
    "# Load in the Dataset\n",
    "predictions_dir = \"../output/positive_evaulation/\"\n",
    "yground = np.load(predictions_dir + \"labels.npy\")\n",
    "ylogits = np.load(predictions_dir + \"pred_results.npy\")\n",
    "ypreds = np.load(predictions_dir + \"ypreds_fpr05.npy\")\n",
    "\n",
    "# Threshold to separate PEAS and PEADS from enhancer_explore.ipynb\n",
    "THRESHOLD = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Sequence Extraction and Visualization\n",
    "MIN_LEN = 12\n",
    "attention_seq(atten_scores, sequences, min_len=MIN_LEN, out_dir=\"../output/attention_seqs/\")\n",
    "\n",
    "from high_attention import plot_line\n",
    "## <preprocess or split your data>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Sequence Extraction from High Attention Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in attention scores from atten.npy\n",
    "attention_file = \"../output/positive_evaulation/heads_atten.npy\"\n",
    "multi_scores = np.load(attention_file)\n",
    "attention_seq(multi_scores, sequences, min_len=MIN_LEN, out_dir=\"../output/attention_seqs/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run FIMO to perform TF enrichment or run through MEME suite to find motif instances."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Motif Regions\n",
    "\n",
    "There are three functions provided: one for plotting single average plots, one for plotting multiple heads, and one for plotting individual attention scores for random samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from high_attention import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metalearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
