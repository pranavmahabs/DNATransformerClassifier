{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Enhancers!\n",
    "\n",
    "This notebook performs downstream analysis using the results from the DNABERT-Enhancer model. In particular, the noteook uses the provided FPR thresholds and classification results to cluster the enhancers into three categories: active, poised enhancers active dissimilar (PEADS), and poised enhancers active similar (peas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the necessary numpy arrays from the evaluation function in `model_src`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Dataset\n",
    "predictions_dir = \"../output/positive_evaulation/\"\n",
    "yground = np.load(predictions_dir + \"labels.npy\")\n",
    "ylogits = np.load(predictions_dir + \"pred_results.npy\")\n",
    "print(f'There are {yground.shape[0]} positive samples being tested.')\n",
    "num_samples = yground.shape[0]\n",
    "\n",
    "print('There are {} poised enhancers'.format(np.count_nonzero(yground == 0))) # num poised\n",
    "print('There are {} active enhancers'.format(np.count_nonzero(yground == 2))) # num active "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Model Results Using FPR Thresholds\n",
    "The accuracy we received is in line with our expectations considering our large sample of negative samples, and the hypothesized similarity between some poised and active enhancers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary Store for FPR Thresholds \n",
    "## Load this from Eval Results JSON file. \n",
    "POISED_THRESHOLDS = {\n",
    "    0.10 : -0.39354804158210754,\n",
    "    0.05 : 0.0886303037405014,\n",
    "    0.03 : 0.34452739357948303,\n",
    "    0.01 : 0.8528411388397217,\n",
    "}\n",
    "\n",
    "ACTIVE_THRESHOLDS = {\n",
    "    0.10 : -0.5178720355033875,\n",
    "    0.05 : -0.11259077489376068,\n",
    "    0.03 : 0.170790046453475952,\n",
    "    0.01 : 0.7585378885269165,\n",
    "}\n",
    "\n",
    "def predict(logits, fpr):\n",
    "    assert fpr in [0.10, 0.05, 0.03, 0.01]\n",
    "\n",
    "    pe_thresh = POISED_THRESHOLDS[fpr]\n",
    "    ae_thresh = ACTIVE_THRESHOLDS[fpr]\n",
    "    if logits[0] > pe_thresh and logits[2] > ae_thresh:\n",
    "        return 0 if logits[0] > logits[2] else 2\n",
    "    elif logits[0] > pe_thresh:\n",
    "        return 0\n",
    "    elif logits[2] > ae_thresh:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Print Out Overall Accuracy\n",
    "fpr = 0.05\n",
    "ypreds = np.apply_along_axis(predict, 1, ylogits, fpr)\n",
    "np.save(os.path.join(\"../output/positive_evaulation/\", \"ypreds_fpr05.npy\"), ypreds)\n",
    "usable_ypreds = np.where(ypreds != 1)[0]\n",
    "\n",
    "fpr_thresh_acc = np.count_nonzero(ypreds == yground) / len(yground)\n",
    "print(f'Accuracy accounting for FPR: {fpr_thresh_acc}')\n",
    "\n",
    "valid_pred = ypreds != 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting AE Scores Across Poised and Active Enhancers\n",
    "\n",
    "Plotting the AE scores for AEs and PEs that were not clasified as noise. We keep misclasified (between PEs and AEs) due to the high AUC scores and the high similarity between AEs and PEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Function Based on Logits - should see clustering. \n",
    "def scale(logits):\n",
    "    norm = np.linalg.norm(logits, 1)\n",
    "    return logits / norm\n",
    "\n",
    "def plot_enhancer(logits, bin_width, enhancer_type, normalized):\n",
    "    assert enhancer_type in [\"Active\", \"Poised\"]\n",
    "\n",
    "    # Define sampls to bin and count\n",
    "    bins = np.arange(np.min(logits), np.max(logits), bin_width)\n",
    "    bin_counts, _ = np.histogram(logits, bins=bins)\n",
    "\n",
    "    plt.bar(bins[:-1], bin_counts, width=bin_width, align='edge', alpha=0.4, color='blue')\n",
    "    plt.plot(bins[:-1] + bin_width/2, bin_counts, color='blue')\n",
    "\n",
    "    plt.xlabel('Acitve Enhancer Score', fontsize=10)\n",
    "    plt.ylabel(f'Number of {enhancer_type} Enhancers', fontsize=10)\n",
    "    plt.xticks(fontsize=9.2)\n",
    "    plt.yticks(fontsize=9.2)\n",
    "    if normalized:\n",
    "        plt.title(f'Normalized Active Enhancer Score versus Number of {enhancer_type} Enhancers', fontsize=12)\n",
    "    else:\n",
    "        plt.title(f'Unnormalized Active Enhancer Score versus Number of {enhancer_type} Enhancers', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_enhancer_special(logits, bin_width, enhancer_type, normalized):\n",
    "    assert enhancer_type in [\"Active\", \"Poised\"]\n",
    "\n",
    "    # Define samples to bin and count\n",
    "    bins = np.arange(np.min(logits), np.max(logits), bin_width)\n",
    "    bin_counts, _ = np.histogram(logits, bins=bins)\n",
    "\n",
    "    # Split the bins and bin_counts into two groups: values under 0 and values greater than or equal to 0\n",
    "    negative_mask = bins[:-1] < 0\n",
    "    positive_mask = bins[:-1] >= 0\n",
    "\n",
    "    # Plot the bars for negative values (color: orange)\n",
    "    plt.bar(bins[:-1][negative_mask], bin_counts[negative_mask], width=bin_width, align='edge', alpha=0.4, color='orange')\n",
    "\n",
    "    # Plot the bars for non-negative values (color: green)\n",
    "    plt.bar(bins[:-1][positive_mask], bin_counts[positive_mask], width=bin_width, align='edge', alpha=0.4, color='green')\n",
    "\n",
    "    # Plot the line plot for negative values (color: orange)\n",
    "    plt.plot(bins[:-1][negative_mask] + bin_width/2, bin_counts[negative_mask], color='orange')\n",
    "\n",
    "    # Plot the line plot for non-negative values (color: green)\n",
    "    plt.plot(bins[:-1][positive_mask] + bin_width/2, bin_counts[positive_mask], color='green')\n",
    "\n",
    "    plt.xlabel('Active Enhancer Score', fontsize=10)\n",
    "    plt.ylabel(f'Number of {enhancer_type} Enhancers', fontsize=10)\n",
    "    plt.xticks(fontsize=9.2)\n",
    "    plt.yticks(fontsize=9.2)\n",
    "    if normalized:\n",
    "        plt.title(f'Normalized Active Enhancer Score versus Number of {enhancer_type} Enhancers', fontsize=12)\n",
    "    else:\n",
    "        plt.title(f'Unnormalized Active Enhancer Score versus Number of {enhancer_type} Enhancers', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_condition = np.logical_and(yground == 2, valid_pred)\n",
    "active_indices = np.where(active_condition)\n",
    "active_logits = ylogits[active_indices]\n",
    "plot_enhancer(active_logits[:,2], 0.025, \"Active\", False)\n",
    "\n",
    "active_normed = np.apply_along_axis(scale, 1, np.delete(active_logits, 1, axis=1))\n",
    "plot_enhancer(active_normed[:,1], 0.025, \"Active\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poised_condition = np.logical_and(yground == 0, valid_pred)\n",
    "poised_indices = np.where(poised_condition)\n",
    "\n",
    "poised_logits = ylogits[poised_indices]\n",
    "plot_enhancer(poised_logits[:,2], 0.025, \"Poised\", False)\n",
    "\n",
    "poised_normed = np.apply_along_axis(scale, 1, np.delete(poised_logits, 1, axis=1))\n",
    "plot_enhancer_special(poised_normed[:,1], 0.025, \"Poised\", True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in all of the Transcription Factor Binding Sites that We Have in a BED File in addition to our positive BED dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pybedtools import BedTool\n",
    "\n",
    "bed_file = \"../analysis/results/comparison_files/EFO-0003042.TFbinding.bed\"\n",
    "tf_sites = list(BedTool(bed_file))\n",
    "\n",
    "tfsites = []\n",
    "with open(bed_file, 'r') as file:\n",
    "    for line in file:\n",
    "        info = line.split()\n",
    "        tfsites.append(info)\n",
    "\n",
    "df_tfsites = pd.DataFrame(tfsites, columns=['Chrom', 'Start', 'End', 'TF'])\n",
    "\n",
    "from pybedtools import BedTool\n",
    "\n",
    "positive_bed = \"../data/positive.bed\"\n",
    "positive_list = list(BedTool(positive_bed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_logits = np.apply_along_axis(scale, 1, np.delete(ylogits, 1, axis=1))\n",
    "active_i = active_indices[0]\n",
    "peads_i = np.where(np.logical_and(poised_condition, normalized_logits[:,1] < 0.0))[0]\n",
    "peas_i = np.where(np.logical_and(poised_condition, normalized_logits[:,1] >= 0.0))[0]\n",
    "\n",
    "assert(len(active_i) + len(peas_i) + len(peads_i) == np.count_nonzero(ypreds != 1))\n",
    "\n",
    "active_b = [positive_list[i] for i in active_i]\n",
    "peads_b = [positive_list[i] for i in peas_i]\n",
    "peas_b = [positive_list[i] for i in peads_i]\n",
    "\n",
    "active_bed = BedTool(active_b)\n",
    "peads_bed = BedTool(peas_b)\n",
    "peas_bed = BedTool(peads_b)\n",
    "\n",
    "active_bed.saveas('../data/active.bed')\n",
    "peads_bed.saveas('../data/peads.bed')\n",
    "peas_bed.saveas('../data/peas.bed')\n",
    "\n",
    "num_active = len(active_i)\n",
    "num_peads = len(peads_i)\n",
    "num_peas = len(peas_i)\n",
    "\n",
    "sizes = {\"Active\" : num_active, \"PEADS\" : num_peads, \"PEAS\" : num_peas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Positive Index to Each of the BED files. \n",
    "\n",
    "def add_index_to_bed(input_file, indices=None, custom_indices=False):\n",
    "    with open(input_file, \"r\") as f:\n",
    "        bed_lines = f.readlines()\n",
    "    if custom_indices:\n",
    "        bed_lines_with_index = [\n",
    "            f\"{line[:-1]}\\t{i}\\n\" for i, line in zip(indices, bed_lines)\n",
    "        ]\n",
    "    else:\n",
    "        bed_lines_with_index = [\n",
    "            f\"{line[:-1]}\\t{i}\\n\" for i, line in enumerate(bed_lines)\n",
    "        ]\n",
    "\n",
    "    with open(f\"{input_file}.indexed\", \"w\") as f:\n",
    "        f.writelines(bed_lines_with_index)\n",
    "\n",
    "add_index_to_bed(\"../data/active.bed\", indices=active_i, custom_indices=True)\n",
    "add_index_to_bed(\"../data/peads.bed\", indices=peads_i, custom_indices=True)\n",
    "add_index_to_bed(\"../data/peas.bed\", indices=peas_i, custom_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data for the three groups\n",
    "group_names = ['Active', 'PEADS', 'PEAS']\n",
    "group_counts = [num_active, num_peads, num_peas]\n",
    "\n",
    "# Use Seaborn's \"pastel\" palette\n",
    "sns.set_palette('pastel')\n",
    "\n",
    "# Create the pie chart\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def autopct_format(values):\n",
    "    def my_format(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct * total / 100.0))\n",
    "        return '{v:d}'.format(v=val)\n",
    "    return my_format\n",
    "\n",
    "plt.pie(group_counts, labels=group_names, autopct=autopct_format(group_counts), textprops={'fontsize': 10}, startangle=90)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Counts of Each Enhancer Type from Positive Dataset', fontsize=12)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "ax.axis('equal')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Enhancer Categories' Enrichment Across Different Transcription Factors\n",
    "Data was acquired from around 80 transcription factors from the ENCODE database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in BED Intersect Files\n",
    "def read_bed(file):\n",
    "    sites = []\n",
    "    with open(file, 'r') as file:\n",
    "        for line in file:\n",
    "            info = line.split()\n",
    "            sites.append(info)\n",
    "    return sites\n",
    "\n",
    "tfactive = read_bed(\"../analysis/results/bed_files/tfbind_active.bed\")\n",
    "tfpeads = read_bed(\"../analysis/results/bed_files/tfbind_peads.bed\")\n",
    "tfpeas = read_bed(\"../analysis/results/bed_files/tfbind_peas.bed\")\n",
    "\n",
    "print(len(tfactive), len(tfpeads), len(tfpeas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explore_utils import process_intersection, determine_fold_change\n",
    "from explore_utils import plot_histogram\n",
    "\n",
    "## Process BEDS\n",
    "map_active, _ = process_intersection(tfactive)\n",
    "map_poised, _ = process_intersection(tfpeads)\n",
    "map_p_to_a, _ = process_intersection(tfpeas)\n",
    "\n",
    "## Set the Exclusion Bound (i.e. how many standard deviations)\n",
    "STDEV_EX = 2.5\n",
    "\n",
    "## Active vs Poised\n",
    "avsp_map = determine_fold_change(map_active, map_poised, \"Active\", \"PEADS\", sizes)\n",
    "# del avsp_map['CBX8']\n",
    "del avsp_map['POLR2AphosphoS5']\n",
    "plot_histogram(avsp_map, \"Active\", \"PEADS\", STDEV_EX)\n",
    "\n",
    "## Active vs PoisedtoActive\n",
    "avspa_map = determine_fold_change(map_active, map_p_to_a, \"Active\", \"PEAS\", sizes)\n",
    "del avspa_map['CBX8']\n",
    "del avspa_map['POLR2AphosphoS5']\n",
    "plot_histogram(avspa_map, \"Active\", \"PEAS\", STDEV_EX)\n",
    "\n",
    "## Poised vs Poised_to_Active\n",
    "pvspa_map = determine_fold_change(map_poised, map_p_to_a, \"PEADS\", \"PEAS\", sizes)\n",
    "del pvspa_map['POLR2AphosphoS5']\n",
    "# plot_histogram(pvspa_map, \"PEADS\", \"PEAS\", STDEV_EX)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating Enhancer Categories with Specific Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Intersect Files generated using Bedtools Intersect\n",
    "ae_cellx = pd.read_csv(\"../analysis/results/bed_files/active_cellintersect.bed\", sep=\"\\t\")\n",
    "ae_cellx.columns = ['Chrom', 'Start', 'End', 'CellID']\n",
    "\n",
    "peads_cellx = pd.read_csv(\"../analysis/results/bed_files/peads_cellintersect.bed\", sep=\"\\t\")\n",
    "peads_cellx.columns = ['Chrom', 'Start', 'End', 'CellID']\n",
    "\n",
    "peas_cellx = pd.read_csv(\"../analysis/results/bed_files/peas_cellintersect.bed\", sep=\"\\t\")\n",
    "peas_cellx.columns = ['Chrom', 'Start', 'End', 'CellID']\n",
    "\n",
    "# Load in Annotation File on 107 Different Cell Types\n",
    "cellid_annot = pd.read_csv(\"../analysis/results/comparison_files/all27ac.cell.anno\", sep='\\t', index_col=0, header=None)\n",
    "cellid_annot.columns=['CellID', 'CellName', 'CellCategory', 'StemProg']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Distribution of PEADS and PEAS Across Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_counts = ae_cellx['CellID'].value_counts() / len(ae_cellx.index)\n",
    "cellid_annot['AEFreq'] = ae_counts\n",
    "\n",
    "peads_counts = peads_cellx['CellID'].value_counts() / len(peads_cellx.index)\n",
    "cellid_annot['PEADSFreq'] = peads_counts\n",
    "\n",
    "peas_counts = peas_cellx['CellID'].value_counts() / len(peas_cellx.index)\n",
    "cellid_annot['PEASFreq'] = peas_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "sns.set(font_scale=0.6)\n",
    "\n",
    "\n",
    "unique_cells = cellid_annot['CellName']\n",
    "x = list(range(len(unique_cells)))\n",
    "bar_width = 0.4\n",
    "\n",
    "plt.bar(x, cellid_annot['PEADSFreq'], width=bar_width, color='blue', label='PEADS Frequency')\n",
    "# Plot the bars for DataFrame 2 (orange bars)\n",
    "plt.bar([i + bar_width for i in x], cellid_annot['PEASFreq'], width=bar_width, color='orange', label='PEAS Frequency')\n",
    "\n",
    "plt.xticks([i + bar_width / 2 for i in x], unique_cells, rotation=60, ha='right') \n",
    "plt.xlabel('Cell Type')\n",
    "plt.ylabel('Category Frequency')\n",
    "plt.title('Distribution of CAEs for PEADs and PEASs')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAttr(cellID, attr):\n",
    "    value = cellid_annot.loc[cellID]\n",
    "    return value[attr]\n",
    "\n",
    "ae_cellx['StemProg'] = ae_cellx['CellID'].map(lambda x: findAttr(x, 'StemProg'), na_action=None)\n",
    "ae_stemprog_counts = ae_cellx['StemProg'].value_counts() / len(ae_cellx.index)\n",
    "\n",
    "peads_cellx['StemProg'] = peads_cellx['CellID'].map(lambda x: findAttr(x, 'StemProg'), na_action=None)\n",
    "peads_stemprog_counts = peads_cellx['StemProg'].value_counts() / len(peads_cellx.index)\n",
    "\n",
    "peas_cellx['StemProg'] = peas_cellx['CellID'].map(lambda x: findAttr(x, 'StemProg'), na_action=None)\n",
    "peas_stemprog_counts = peas_cellx['StemProg'].value_counts() / len(peas_cellx.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [ae_stemprog_counts, peads_stemprog_counts, peas_stemprog_counts]\n",
    "values_normal = [count['normal'] for count in counts]\n",
    "values_cancer = [count['cancer'] for count in counts]\n",
    "values_stem = [count['stem'] for count in counts]\n",
    "values_progenitor = [count['progenitor'] for count in counts]\n",
    "\n",
    "# Get the unique categories for the x-axis labels\n",
    "categories = ['AE', 'PEADS', 'PEAS']\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Set the positions for the bars on the x-axis\n",
    "x_normal = range(len(categories))\n",
    "x_cancer = [i + bar_width for i in x_normal]\n",
    "x_stem = [i + bar_width*2 for i in x_normal]\n",
    "x_progenitor = [i + bar_width*3 for i in x_normal]\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_normal, values_normal, width=bar_width, color='blue', label='Normal')\n",
    "plt.bar(x_cancer, values_cancer, width=bar_width, color='orange', label='Cancer')\n",
    "plt.bar(x_stem, values_stem, width=bar_width, color='green', label='Stem')\n",
    "plt.bar(x_progenitor, values_progenitor, width=bar_width, color='red', label='Progenitor')\n",
    "\n",
    "# Set x-axis labels and ticks\n",
    "plt.xticks([i + bar_width*1.5 for i in x_normal], categories)\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Occurrences Count')\n",
    "plt.title('Occurrences of Each Key in Different Categories')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparitive PWM/Motif Enrichment Across Enhancer Categories\n",
    "\n",
    "This analysis uses motifs and PWMs derived from the ENCODE database that were used in a FIMO run alongside FA files generated from high attention regions in `attent_explore.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the TSVs from FIMO that contain all of the PWM enrichment data.\n",
    "ae_motifs = pd.read_csv(\"./results/fimo/active/fimo.tsv\", sep=\"\\t\", header=0, skipfooter=3, skip_blank_lines=True, engine='python')\n",
    "peads_motifs = pd.read_csv(\"./results/fimo/peads/fimo.tsv\", sep=\"\\t\", header=0, skipfooter=3, skip_blank_lines=True, engine='python')\n",
    "peas_motifs = pd.read_csv(\"./results/fimo/peas/fimo.tsv\", sep=\"\\t\", header=0, skipfooter=3, skip_blank_lines=True, engine='python')\n",
    "\n",
    "negative_motifs = pd.read_csv(\"./results/fimo/neg/fimo.tsv\", sep=\"\\t\", header=0, skipfooter=3, skip_blank_lines=True, engine='python') # need to acquire negative set from biowulf to run a FIMO run \n",
    "neg_total_seq_len = (17 + 19 + 21 + 25 + 35) * 9000\n",
    "print(\"Total Sequence Length for Negative Hits: {}\".format(neg_total_seq_len))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quantify enrichment we will divide the number of hits for each motif by the average sequence length of the high attention regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_grouped = ae_motifs.groupby('motif_id')\n",
    "peads_grouped = peads_motifs.groupby('motif_id')\n",
    "peas_grouped = peas_motifs.groupby('motif_id')\n",
    "\n",
    "negative_grouped = negative_motifs.groupby('motif_id')\n",
    "\n",
    "ae_pwm_map = {}\n",
    "\n",
    "def determine_length(df, custom_format = True):\n",
    "    all_seqs = (df['sequence_name']).unique()\n",
    "\n",
    "    total_length = 0\n",
    "    for seq in all_seqs:\n",
    "        if custom_format:\n",
    "            # sequence_start_end format\n",
    "            vals = seq.split('_')\n",
    "            seq_len = int(vals[2]) - int(vals[1])\n",
    "        else:\n",
    "            # chr:start-end format\n",
    "            coords = ((seq.split(\":\"))[1]).split('-')\n",
    "            seq_len = int(coords[1]) - int(coords[0])\n",
    "        total_length += seq_len\n",
    "    return total_length\n",
    "\n",
    "def create_pwm(grouped_df, length):\n",
    "    this_map = {}\n",
    "    for tf, group in grouped_df:\n",
    "        count = group.shape[0]\n",
    "        if pd.isnull(group.iloc[0][\"motif_alt_id\"]):\n",
    "            this_map[tf] = count / length\n",
    "        else:\n",
    "            this_map[group.iloc[0][\"motif_alt_id\"]] = count / length\n",
    "        # print(\"Unique Value {}, Count {}\".format(tf, count))\n",
    "    return this_map\n",
    "\n",
    "\n",
    "print([determine_length(i) for i in [ae_motifs, peads_motifs, peas_motifs]])\n",
    "print(determine_length(negative_motifs, False))\n",
    "\n",
    "ae_length = determine_length(ae_motifs)\n",
    "ae_map = create_pwm(ae_grouped, ae_length)\n",
    "\n",
    "peads_length = determine_length(peads_motifs)\n",
    "peads_map = create_pwm(peads_grouped, peads_length)\n",
    "\n",
    "peas_length = determine_length(peas_motifs)\n",
    "peas_map = create_pwm(peas_grouped, peas_length)\n",
    "\n",
    "negative_length = determine_length(negative_motifs, False)\n",
    "negative_map = create_pwm(negative_grouped, negative_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest = 'Egr1_primary'\n",
    "print(\"{} - Active: {}\\t PEADS: {}\\t PEAS: {}\\t Negative: {}\".format(\n",
    "    interest, ae_map[interest], peads_map[interest], peas_map[interest], negative_map[interest]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs_interest = ['CTCF_full', 'KDM2B', 'Egr1_primary', 'NRF1_full', 'SP1', 'POU5F1', 'EP300.p2', 'BACH1', 'BACH2', 'MAX', 'REST.p3', 'MXI1', 'TEAD4', 'BRCA1', 'SRF', 'GABPA', 'CEBPB', 'SP4', 'MYC', 'USF2', 'SIX5', 'ZNF143.p2']\n",
    "\n",
    "def safe_find(mp, key):\n",
    "    if key not in mp:\n",
    "        return 0\n",
    "    else:\n",
    "        return mp[key]\n",
    "\n",
    "ae_motifscores = [safe_find(ae_map, motif) for motif in motifs_interest]\n",
    "peads_motifscores = [safe_find(peads_map, motif) for motif in motifs_interest]\n",
    "peas_motifscores = [safe_find(peas_map, motif) for motif in motifs_interest]\n",
    "negative_motifscores = [safe_find(negative_map, motif) for motif in motifs_interest]\n",
    "\n",
    "ae_motiffold = [(ae / neg) for ae, neg in zip(ae_motifscores, negative_motifscores)]\n",
    "peads_motiffold = [(ae / neg) for ae, neg in zip(peads_motifscores, negative_motifscores)]\n",
    "peas_motiffold = [(ae / neg) for ae, neg in zip(peas_motifscores, negative_motifscores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "pwms = pd.DataFrame({\n",
    "    \"Motifs\": motifs_interest,\n",
    "    # 'Negative': negative_motifscores,\n",
    "    'Active': ae_motiffold,\n",
    "    'PEADS': peads_motiffold,\n",
    "    'PEAS': peas_motiffold\n",
    "})\n",
    "\n",
    "pwms.set_index('Motifs', inplace=True)\n",
    "\n",
    "pwms_log = pwms.applymap(lambda x: -5 if x == 0 else -5 if x < 0 else round(math.log(x), 2))\n",
    "\n",
    "plt.figure(figsize=(6, 12))\n",
    "sns.heatmap(pwms, cmap='viridis', annot=True, fmt=\".2f\", vmax=8)\n",
    "# sns.heatmap(pwms, cmap='coolwarm', annot=True, fmt=\".2f\", center=1)\n",
    "plt.title('PWM Enrichment Heatmap Shown Through Fold Change')\n",
    "plt.xlabel('Enhancer Category')\n",
    "plt.ylabel('Motif')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metalearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
