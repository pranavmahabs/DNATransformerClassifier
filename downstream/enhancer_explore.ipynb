{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ylabel', 'ypred']\n",
      "There are 26157 positive samples being tested.\n"
     ]
    }
   ],
   "source": [
    "# Load in the Dataset\n",
    "predictions_file = \"/Users/pranavmahableshwarkar/CS/NIH/DNATransformerClassifier/data/positive.bed.prediction.hdf5\"\n",
    "f = h5py.File(predictions_file, 'r')\n",
    "print(list(f.keys()))\n",
    "yground = np.array(f['ylabel'][:]) + 1\n",
    "ylogits = np.array(f['ypred'][:])\n",
    "print(f'There are {yground.shape[0]} positive samples being tested.')\n",
    "num_samples = yground.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionary Store for FPR Thresholds\n",
    "POISED_THRESHOLDS = {\n",
    "    0.10 : 0.035881,\n",
    "    0.05 : 0.082293,\n",
    "    0.03 : 0.138684,\n",
    "    0.01 : 0.357510,\n",
    "}\n",
    "\n",
    "ACTIVE_THRESHOLDS = {\n",
    "    0.10 : 0.021631,\n",
    "    0.05 : 0.062012,\n",
    "    0.03 : 0.119902,\n",
    "    0.01 : 0.297552,\n",
    "}\n",
    "\n",
    "def predict(logits, fpr):\n",
    "    assert fpr in [0.10, 0.05, 0.03, 0.01]\n",
    "\n",
    "    pe_thresh = POISED_THRESHOLDS[fpr]\n",
    "    ae_thresh = ACTIVE_THRESHOLDS[fpr]\n",
    "    if logits[0] > pe_thresh and logits[2] > ae_thresh:\n",
    "        return 0 if logits[0] > logits[2] else 2\n",
    "    elif logits[0] > pe_thresh:\n",
    "        return 0\n",
    "    elif logits[2] > ae_thresh:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy accounting for FPR: 0.5693313453377681\n"
     ]
    }
   ],
   "source": [
    "# First Print Out Overall Accuracy\n",
    "fpr = 0.05\n",
    "ypreds = np.apply_along_axis(predict, 1, ylogits, fpr)\n",
    "\n",
    "fpr_thresh_acc = np.count_nonzero(ypreds == yground) / len(yground)\n",
    "print(f'Accuracy accounting for FPR: {fpr_thresh_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Function Based on Logits - should see clustering. \n",
    "def scale(logits):\n",
    "    norm = np.linalg.norm(logits, 1)\n",
    "    return logits / norm\n",
    "\n",
    "def plot_enhancer(logits, bin_width, enhancer_type):\n",
    "    assert enhancer_type in [\"Active\", \"Poised\"]\n",
    "\n",
    "    # Define sampls to bin and count\n",
    "    bins = np.arange(0, 1 + bin_width, bin_width)\n",
    "    bin_counts, _ = np.histogram(logits, bins=bins)\n",
    "\n",
    "    plt.bar(bins[:-1], bin_counts, width=bin_width, align='edge', alpha=0.4, color='blue')\n",
    "    plt.plot(bins[:-1] + bin_width/2, bin_counts, color='blue')\n",
    "\n",
    "    # cumulative = np.cumsum(bin_counts)\n",
    "    # cumul_norm = (cumulative / cumulative[-1]) * max(bin_counts)\n",
    "    # plt.plot(bins[:-1] + bin_width/2, cumul_norm, color='red')\n",
    "\n",
    "    plt.xlabel('Acitve Enhancer Score')\n",
    "    plt.ylabel(f'Number of {enhancer_type} Enhancers')\n",
    "    plt.title(f'Active Enhancer Score versus Number of {enhancer_type} Enhancers')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_indices = np.where(yground == 2)\n",
    "active_logits = ylogits[active_indices]\n",
    "# plot_enhancer(active_logits[:,2], 0.025, \"Active\")\n",
    "\n",
    "active_normed = np.apply_along_axis(scale, 1, np.delete(active_logits, 1, axis=1))\n",
    "# plot_enhancer(active_normed[:,1], 0.025, \"Active\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poised_indices = np.where(yground == 0)\n",
    "poised_logits = ylogits[poised_indices]\n",
    "# plot_enhancer(poised_logits[:,2], 0.025, \"Poised\")\n",
    "\n",
    "poised_normed = np.apply_along_axis(scale, 1, np.delete(poised_logits, 1, axis=1))\n",
    "# plot_enhancer(poised_normed[:,1], 0.025, \"Poised\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot visualizing percentage AE and PE. Should see three clusters??\n",
    "def scale(logits):\n",
    "    norm = np.linalg.norm(logits, 1)\n",
    "    return logits / norm\n",
    "\n",
    "def scatter_enhancer(raw_logits):\n",
    "    # Delete the noise column\n",
    "    no_noise = np.delete(raw_logits, 1, axis=1)\n",
    "    # no_noise = np.apply_along_axis(scale, 1, no_noise)\n",
    "\n",
    "    x = no_noise[:,0]\n",
    "    y = no_noise[:,1]\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "    plt.title(f'All {num_samples} Scattered Along Percent AE and PE from CNN Model')\n",
    "    plt.xlabel(\"Percent PE\")\n",
    "    plt.ylabel(\"Percent AE\")\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_enhancer(ylogits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Interval(chr1:180593-181003), Interval(chr1:180694-180954)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pybedtools import BedTool\n",
    "\n",
    "bed_file = \"/Users/pranavmahableshwarkar/CS/NIH/DNATransformerClassifier/data/EFO-0003042.TFbinding.bed\"\n",
    "tf_sites = list(BedTool(bed_file))\n",
    "\n",
    "print(tf_sites[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfsites = []\n",
    "with open(bed_file, 'r') as file:\n",
    "    for line in file:\n",
    "        info = line.split()\n",
    "        tfsites.append(info)\n",
    "\n",
    "df_tfsites = pd.DataFrame(tfsites, columns=['Chrom', 'Start', 'End', 'TF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfsites\n",
    "yground[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metalearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
